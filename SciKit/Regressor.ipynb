{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import datasets, neighbors\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_regressor(y_test_pred, X_test, y_test):\n",
    "    plt.scatter(X_test, y_test, color='green')\n",
    "    plt.plot(X_test, y_test_pred, color='black', linewidth=4)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/clast.txt\"\n",
    "data = np.loadtxt(input_file, delimiter=',')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "Х, у = shuffle(X, random_state=7), shuffle(y, random_state=7) #перемешивание\n",
    "num_training = int(0.8 * len(X))\n",
    "num_test = len(X) - num_training\n",
    "X_train, y_train = X[:num_training], y[:num_training]\n",
    "X_test, y_test = X[num_training:], y[num_training:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regressor\n",
    "regressor = linear_model.LinearRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Polynomial regressor\n",
    "regressor = linear_model.LinearRegression()\n",
    "polynomial = PolynomialFeatures(degree=6)\n",
    "X_train = polynomial.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Machine of vectors regressor\n",
    "regressor = SVR(kernel='linear', C=1.0, epsilon=10.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tree regressor with AdaBoostRegressor\n",
    "regressor = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=100, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extra trees regressor\n",
    "params = { 'n_estimators': 100, 'max_depth': 4, 'random_state': 0}\n",
    "regressor = ExtraTreesRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neighbors regressor\n",
    "num_neighbors = 10\n",
    "regressor = neighbors.KNeighborsRegressor(num_neighbors, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.08]\n",
      " [ 2.05]\n",
      " [ 4.53]\n",
      " [ 6.23]\n",
      " [ 5.35]\n",
      " [ 2.88]\n",
      " [ 2.32]\n",
      " [ 5.06]\n",
      " [ 5.38]\n",
      " [ 6.31]\n",
      " [ 3.41]\n",
      " [ 1.75]\n",
      " [ 3.88]\n",
      " [ 7.22]\n",
      " [ 5.85]\n",
      " [ 3.66]\n",
      " [ 0.45]\n",
      " [ 6.01]\n",
      " [ 7.06]\n",
      " [ 7.47]\n",
      " [ 2.2 ]\n",
      " [ 2.94]\n",
      " [ 5.87]\n",
      " [ 4.57]\n",
      " [ 5.84]\n",
      " [ 3.4 ]\n",
      " [ 1.44]\n",
      " [ 4.29]\n",
      " [ 8.09]\n",
      " [ 6.48]\n",
      " [ 2.94]\n",
      " [ 0.41]\n",
      " [ 5.42]\n",
      " [ 7.47]\n",
      " [ 5.62]\n",
      " [ 3.71]\n",
      " [ 0.41]\n",
      " [ 4.93]\n",
      " [ 7.23]\n",
      " [ 6.77]\n",
      " [ 3.23]\n",
      " [ 1.61]\n",
      " [ 4.7 ]\n",
      " [ 6.86]\n",
      " [ 5.2 ]\n",
      " [ 1.53]\n",
      " [ 0.27]\n",
      " [ 6.17]\n",
      " [ 8.47]\n",
      " [ 5.23]\n",
      " [ 3.27]\n",
      " [ 1.52]\n",
      " [ 5.49]\n",
      " [ 5.47]\n",
      " [ 5.43]\n",
      " [ 2.51]\n",
      " [ 2.07]\n",
      " [ 5.21]\n",
      " [ 7.05]\n",
      " [ 6.09]\n",
      " [ 2.65]\n",
      " [ 3.18]\n",
      " [ 5.11]\n",
      " [ 7.87]\n",
      " [ 6.51]\n",
      " [ 2.72]\n",
      " [ 1.79]\n",
      " [ 4.48]\n",
      " [ 5.7 ]\n",
      " [ 7.43]\n",
      " [ 3.25]\n",
      " [ 2.47]\n",
      " [ 4.36]\n",
      " [ 6.75]\n",
      " [ 7.81]\n",
      " [ 1.98]\n",
      " [ 2.07]\n",
      " [ 5.18]\n",
      " [ 6.52]\n",
      " [ 5.49]\n",
      " [ 2.93]\n",
      " [ 1.81]\n",
      " [ 6.22]\n",
      " [ 7.31]\n",
      " [ 7.41]\n",
      " [ 2.89]\n",
      " [ 3.03]\n",
      " [ 6.31]\n",
      " [ 7.63]\n",
      " [ 5.99]\n",
      " [ 2.38]\n",
      " [ 1.98]\n",
      " [ 3.81]\n",
      " [ 6.67]\n",
      " [ 8.17]\n",
      " [ 2.37]\n",
      " [ 2.62]\n",
      " [ 5.6 ]\n",
      " [ 6.47]\n",
      " [ 4.48]\n",
      " [ 2.91]\n",
      " [ 2.13]\n",
      " [ 4.01]\n",
      " [ 7.55]\n",
      " [ 6.65]\n",
      " [ 4.13]\n",
      " [ 0.67]\n",
      " [ 4.47]\n",
      " [ 7.18]\n",
      " [ 6.  ]\n",
      " [ 3.89]\n",
      " [ 2.82]\n",
      " [ 4.97]\n",
      " [ 6.56]\n",
      " [ 5.52]\n",
      " [ 2.8 ]\n",
      " [ 1.49]\n",
      " [ 3.59]\n",
      " [ 7.07]\n",
      " [ 5.43]\n",
      " [ 2.94]\n",
      " [ 2.3 ]\n",
      " [ 4.79]\n",
      " [ 7.37]\n",
      " [ 7.38]\n",
      " [ 1.78]\n",
      " [ 2.33]\n",
      " [ 5.88]\n",
      " [ 6.86]\n",
      " [ 6.74]\n",
      " [ 2.97]\n",
      " [ 2.06]\n",
      " [ 3.79]\n",
      " [ 7.4 ]\n",
      " [ 6.7 ]\n",
      " [ 2.21]\n",
      " [ 1.48]\n",
      " [ 3.18]\n",
      " [ 8.3 ]\n",
      " [ 6.78]\n",
      " [ 3.92]\n",
      " [ 1.53]\n",
      " [ 5.2 ]\n",
      " [ 6.98]\n",
      " [ 5.  ]\n",
      " [ 2.47]\n",
      " [ 1.18]\n",
      " [ 4.76]\n",
      " [ 7.87]\n",
      " [ 6.11]\n",
      " [ 3.47]\n",
      " [ 1.95]\n",
      " [ 5.14]\n",
      " [ 7.2 ]\n",
      " [ 5.95]\n",
      " [ 2.38]\n",
      " [ 2.43]\n",
      " [ 5.72]\n",
      " [ 7.73]\n",
      " [ 6.69]\n",
      " [ 2.64]\n",
      " [ 1.97]\n",
      " [ 4.87]\n",
      " [ 6.5 ]\n",
      " [ 6.97]\n",
      " [ 2.18]\n",
      " [ 1.5 ]\n",
      " [ 4.51]\n",
      " [ 8.63]\n",
      " [ 6.16]\n",
      " [ 3.62]\n",
      " [ 2.43]\n",
      " [ 5.03]\n",
      " [ 7.2 ]\n",
      " [ 6.26]\n",
      " [ 2.9 ]\n",
      " [ 1.43]\n",
      " [ 2.95]\n",
      " [ 7.34]\n",
      " [ 7.74]\n",
      " [ 4.1 ]\n",
      " [ 2.03]\n",
      " [ 5.25]\n",
      " [ 5.98]\n",
      " [ 4.28]\n",
      " [ 2.73]\n",
      " [ 3.6 ]\n",
      " [ 5.85]\n",
      " [ 7.32]\n",
      " [ 6.39]\n",
      " [ 1.72]\n",
      " [ 2.28]\n",
      " [ 4.29]\n",
      " [ 6.31]\n",
      " [ 5.54]\n",
      " [ 2.24]\n",
      " [ 1.99]\n",
      " [ 6.16]\n",
      " [ 7.83]\n",
      " [ 7.  ]\n",
      " [ 2.95]\n",
      " [ 1.22]\n",
      " [ 5.07]\n",
      " [ 6.84]\n",
      " [ 6.23]\n",
      " [ 3.06]\n",
      " [ 2.62]\n",
      " [ 3.96]\n",
      " [ 6.96]\n",
      " [ 6.95]\n",
      " [ 4.13]\n",
      " [ 1.99]\n",
      " [ 3.  ]\n",
      " [ 7.01]\n",
      " [ 6.46]\n",
      " [ 2.43]\n",
      " [ 2.84]\n",
      " [ 4.48]\n",
      " [ 5.57]\n",
      " [ 5.67]\n",
      " [ 3.15]\n",
      " [-0.4 ]\n",
      " [ 5.07]\n",
      " [ 6.73]\n",
      " [ 5.48]\n",
      " [ 3.13]\n",
      " [ 1.71]\n",
      " [ 4.96]\n",
      " [ 6.64]\n",
      " [ 6.22]\n",
      " [ 3.25]\n",
      " [ 1.92]\n",
      " [ 3.65]\n",
      " [ 6.78]\n",
      " [ 5.13]\n",
      " [ 4.05]\n",
      " [ 2.96]\n",
      " [ 5.4 ]\n",
      " [ 7.18]\n",
      " [ 6.35]\n",
      " [ 3.12]\n",
      " [ 2.14]\n",
      " [ 5.3 ]\n",
      " [ 7.96]\n",
      " [ 5.04]\n",
      " [ 3.35]\n",
      " [ 2.41]\n",
      " [ 4.77]\n",
      " [ 8.33]\n",
      " [ 6.33]\n",
      " [ 2.97]\n",
      " [ 2.1 ]\n",
      " [ 5.15]\n",
      " [ 6.12]\n",
      " [ 5.69]\n",
      " [ 2.66]\n",
      " [ 2.58]\n",
      " [ 3.69]\n",
      " [ 7.91]\n",
      " [ 6.41]\n",
      " [ 3.4 ]\n",
      " [ 1.78]\n",
      " [ 4.16]\n",
      " [ 8.12]\n",
      " [ 6.49]\n",
      " [ 2.69]\n",
      " [ 2.14]\n",
      " [ 3.37]\n",
      " [ 5.48]\n",
      " [ 5.7 ]\n",
      " [ 2.75]\n",
      " [ 2.41]\n",
      " [ 5.2 ]\n",
      " [ 8.32]\n",
      " [ 5.62]\n",
      " [ 1.71]\n",
      " [ 4.28]\n",
      " [ 4.58]\n",
      " [ 6.65]\n",
      " [ 6.21]] [ 1.05  7.7   5.49  1.02  7.86  0.79  8.5   5.65  3.53  9.73  2.05  7.38\n",
      "  5.73  2.88  9.11  2.38  7.99  5.83  2.41  8.97  2.71  8.71  4.56  1.33\n",
      "  6.54  1.    8.26  4.69  1.99  9.44  1.78  9.14  4.08  2.15  7.65  1.26\n",
      "  8.9   5.73  0.14  9.09  2.64  7.85  4.78  2.21  9.65  2.93  9.38  5.74\n",
      "  2.44  7.41  1.63  8.8   4.5   2.81  7.45  2.84  7.67  3.99  3.    9.39\n",
      "  2.46  8.62  4.49  1.69  8.04  1.67  7.94  6.06  2.29  8.76  2.99  7.78\n",
      "  6.1   0.96  7.9   1.96  7.9   7.47  3.06  9.55  2.61  9.27  4.35  3.41\n",
      "  9.02  2.36  8.08  5.32  1.3   8.5   2.42  8.09  5.2   2.11  8.57  0.62\n",
      "  7.26  4.33  1.77  8.55  2.16  8.64  4.24  2.06  8.99  1.76  7.53  4.57\n",
      "  3.    8.5   3.09  7.58  4.67  2.24  8.23  1.41  7.08  6.74  1.07  8.66\n",
      "  2.23  8.8   3.84  1.64  7.37  2.    8.15  5.78  3.37  9.56  0.43  9.18\n",
      "  5.    2.94  9.66  1.08  6.75  5.36  2.54  8.1   1.94  7.74  3.8   3.27\n",
      "  7.96  1.18  8.39  4.11  1.52  8.46  2.11  8.25  6.24  2.76  8.97  3.12\n",
      "  9.13  6.07  1.82  8.79  2.08  8.67  4.65  2.89  7.82  2.97  7.46  5.35\n",
      "  1.22  8.02  1.02  8.03  5.65  0.99  8.23  2.19  7.25  5.06 -0.29  7.58\n",
      "  1.18  7.97  3.69  2.28  8.34  0.95  7.48  4.74  1.86 10.29  2.47  6.28\n",
      "  3.8   2.32  8.5   1.06  8.47  6.37  2.99 10.32  0.95  7.99  3.88  1.41\n",
      "  8.73  1.76  8.    3.63  1.18  7.74  1.52  7.35  4.86  1.86 10.2   2.99\n",
      "  8.28  4.89  1.95  8.35  3.19  6.    5.03  3.09  8.47  2.67  8.96  4.71\n",
      "  0.64  8.76  1.56  7.36  6.42  1.34  8.29  3.39  7.27  3.25  1.88  8.76\n",
      "  1.8   7.26  6.22  2.05  8.29  2.25  7.15  5.88  0.8   7.89  1.6   9.45\n",
      "  4.64  1.15  7.85  1.65  9.44  6.13  1.87  8.98  2.29  8.41  5.54  1.47\n",
      "  9.06  0.11  7.91  4.54  2.5   8.79  1.54  8.53  6.55  2.52  8.16  1.31\n",
      "  8.78  5.78  1.6   8.06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train, y_train)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.47]\n",
      " [ 2.42]\n",
      " [ 4.5 ]\n",
      " [ 6.8 ]\n",
      " [ 6.  ]\n",
      " [ 2.74]\n",
      " [ 3.62]\n",
      " [ 4.36]\n",
      " [ 6.8 ]\n",
      " [ 5.78]\n",
      " [ 3.53]\n",
      " [ 2.33]\n",
      " [ 5.76]\n",
      " [ 5.96]\n",
      " [ 6.84]\n",
      " [ 3.43]\n",
      " [ 0.85]\n",
      " [ 6.05]\n",
      " [ 7.73]\n",
      " [ 6.77]\n",
      " [ 3.47]\n",
      " [-0.09]\n",
      " [ 6.21]\n",
      " [ 7.7 ]\n",
      " [ 5.13]\n",
      " [ 3.  ]\n",
      " [ 3.06]\n",
      " [ 5.85]\n",
      " [ 6.73]\n",
      " [ 5.62]\n",
      " [ 2.  ]\n",
      " [ 2.42]\n",
      " [ 4.14]\n",
      " [ 6.65]\n",
      " [ 5.88]\n",
      " [ 4.21]\n",
      " [ 3.05]\n",
      " [ 5.69]\n",
      " [ 7.44]\n",
      " [ 6.55]\n",
      " [ 3.37]\n",
      " [ 1.57]\n",
      " [ 5.46]\n",
      " [ 7.45]\n",
      " [ 5.59]\n",
      " [ 2.51]\n",
      " [ 2.85]\n",
      " [ 5.12]\n",
      " [ 6.54]\n",
      " [ 5.92]\n",
      " [ 3.23]\n",
      " [ 2.02]\n",
      " [ 4.69]\n",
      " [ 7.57]\n",
      " [ 6.76]\n",
      " [ 2.22]\n",
      " [ 0.15]\n",
      " [ 3.72]\n",
      " [ 7.33]\n",
      " [ 6.27]\n",
      " [ 4.59]\n",
      " [ 1.72]\n",
      " [ 4.3 ]\n",
      " [ 7.43]\n",
      " [ 5.83]\n",
      " [ 2.92]\n",
      " [ 3.1 ]\n",
      " [ 5.83]\n",
      " [ 6.54]\n",
      " [ 5.6 ]] [5.57056912 5.58093518 5.1497072  4.67286857 4.83872549 5.51459242\n",
      " 5.33214981 5.17873216 4.67286857 4.88433614 5.35080871 5.59959408\n",
      " 4.88848256 4.84701833 4.66457573 5.37154083 5.90642938 4.82835943\n",
      " 4.48005991 4.67908821 5.36324798 6.10131125 4.79518805 4.48627955\n",
      " 5.01909488 5.46068892 5.44824965 4.86982366 4.68738105 4.91750752\n",
      " 5.66801006 5.58093518 5.22434281 4.70396675 4.86360403 5.20983033\n",
      " 5.45032286 4.90299504 4.54018304 4.72469886 5.38398009 5.75715815\n",
      " 4.95067891 4.53810983 4.92372716 5.56227628 5.49178709 5.02116809\n",
      " 4.72677207 4.85531118 5.41300505 5.66386364 5.11031619 4.51323129\n",
      " 4.68116142 5.62239941 6.05155418 5.31141769 4.56298837 4.78274878\n",
      " 5.1310483  5.72605998 5.19117143 4.54225625 4.87397008 5.47727461\n",
      " 5.4399568  4.87397008 4.72677207 4.92165395]\n",
      "error: 173.2657601587564\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = regressor.predict(X_test)\n",
    "error = sum(abs(y_test-y_test_pred))\n",
    "print(\"error:\",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEEgA4ASBDIAKEEgA4AS/wfV+4Xmd2mlwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204b37d3828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_regressor(y_test_pred, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "output_model_file = 'saves/model.pkl' \n",
    "with open(output_model_file, 'wb') as f:\n",
    "    pickle.dump(regressor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open model\n",
    "output_model_file = 'saves/amodel.pkl' \n",
    "with open(output_model_file, 'rb') as f:\n",
    "    regressor = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
